# ë¹…í…Œí¬ ìˆ˜ì¤€ì˜ ë°°ì¹˜ ì„±ëŠ¥ ë¶„ì„ ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ: "ëŠë¦¬ë‹¤"ê°€ ì•„ë‹ˆë¼ "ì™œ ëŠë¦°ê°€"ë¥¼ ë°ì´í„°ë¡œ ì¦ëª…

---

## ğŸ“Š ìˆ˜ì§‘í•´ì•¼ í•  í•µì‹¬ ë©”íŠ¸ë¦­

### 1. ì»´í“¨íŒ… íš¨ìœ¨ì„± (Resource Saturation)

**ì§ˆë¬¸:** "CPUê°€ 100% ëŒì•„ì„œ ëŠë¦°ê°€? ì•„ë‹ˆë©´ ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸°ë¡œ ëŠë¦°ê°€?"

#### ì¸¡ì • í•­ëª©
- **CPU ì‚¬ìš©ë¥ ** (ëª©í‘œ: 70-80%)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ** (ëª©í‘œ: 70-80%)
- **ë„¤íŠ¸ì›Œí¬ I/O** (ì™¸ë¶€ API ëŒ€ê¸° ì‹œê°„)
- **ë””ìŠ¤í¬ I/O** (DB ì¿¼ë¦¬ ëŒ€ê¸° ì‹œê°„)
- **ìŠ¤ë ˆë“œ ìƒíƒœ** (RUNNABLE vs WAITING)

---

### 2. ë°ì´í„° ìŠ¤í (Data Skew)

**ì§ˆë¬¸:** "íŠ¹ì • íšŒì‚¬ë§Œ ì˜¤ë˜ ê±¸ë ¤ì„œ ì „ì²´ê°€ ëŠë¦°ê°€?"

#### ì¸¡ì • í•­ëª©
- **íšŒì‚¬ë³„ ì²˜ë¦¬ ì‹œê°„** (ìµœì†Œ/ìµœëŒ€/ì¤‘ê°„ê°’/í‘œì¤€í¸ì°¨)
- **ì²˜ë¦¬ ì‹œê°„ ë¶„í¬** (íˆìŠ¤í† ê·¸ë¨)
- **Long Tail ë¶„ì„** (ìƒìœ„ 20% íšŒì‚¬ê°€ ì „ì²´ ì‹œê°„ì˜ 80% ì°¨ì§€í•˜ëŠ”ê°€?)

---

### 3. ë¹„ìš© íš¨ìœ¨ì„± (Cost per Record)

**ì§ˆë¬¸:** "ë°ì´í„° 1ê±´ ì²˜ë¦¬ì— ì–¼ë§ˆì˜ ë¹„ìš©ì´ ë“œëŠ”ê°€?"

#### ì¸¡ì • í•­ëª©
- **ì¸í”„ë¼ ë¹„ìš© / ì²˜ë¦¬ ê±´ìˆ˜** ($ per post)
- **Gemini API ë¹„ìš© / ìš”ì•½ ê±´ìˆ˜**
- **EC2 ì‹œê°„ë‹¹ ë¹„ìš© / ì²˜ë¦¬ ì†ë„**
- **ì›”ë³„ ë¹„ìš© ì¶”ì´**

---

## ğŸ›  ì¸¡ì • ë„êµ¬

### ë„êµ¬ 1: ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¶”ê°€ (Spring Boot Actuator + Micrometer)

#### Step 1: Dependency ì¶”ê°€

```kotlin
// build.gradle.kts
dependencies {
    // ê¸°ì¡´ dependencies...

    // Actuator (ë©”íŠ¸ë¦­ ìˆ˜ì§‘)
    implementation("org.springframework.boot:spring-boot-starter-actuator")

    // Micrometer (ë©”íŠ¸ë¦­ export)
    implementation("io.micrometer:micrometer-registry-prometheus")

    // JVM ë©”íŠ¸ë¦­
    runtimeOnly("io.micrometer:micrometer-core")
}
```

#### Step 2: application.yml ì„¤ì •

```yaml
# batch/src/main/resources/application.yml

management:
  endpoints:
    web:
      exposure:
        include: health,metrics,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: batch
      environment: production

  # JVM ë©”íŠ¸ë¦­ í™œì„±í™”
  metrics:
    enable:
      jvm: true
      process: true
      system: true
```

#### Step 3: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ Listener

```kotlin
// batch/src/main/kotlin/com/techinsights/batch/listener/ResourceMetricsListener.kt

package com.techinsights.batch.listener

import io.micrometer.core.instrument.MeterRegistry
import io.micrometer.core.instrument.Timer
import org.springframework.batch.core.JobExecution
import org.springframework.batch.core.JobExecutionListener
import org.springframework.batch.core.StepExecution
import org.springframework.batch.core.StepExecutionListener
import org.springframework.stereotype.Component
import java.lang.management.ManagementFactory
import java.time.Duration

@Component
class ResourceMetricsListener(
    private val meterRegistry: MeterRegistry
) : JobExecutionListener, StepExecutionListener {

    private val runtime = Runtime.getRuntime()
    private val osBean = ManagementFactory.getOperatingSystemMBean()
    private val threadBean = ManagementFactory.getThreadMXBean()

    private data class ResourceSnapshot(
        val timestamp: Long,
        val cpuLoad: Double,
        val memoryUsed: Long,
        val memoryFree: Long,
        val threadCount: Int,
        val waitingThreads: Int
    )

    private var jobStartSnapshot: ResourceSnapshot? = null
    private val stepSnapshots = mutableMapOf<Long, ResourceSnapshot>()

    override fun beforeJob(jobExecution: JobExecution) {
        jobStartSnapshot = captureResourceSnapshot()

        log.info("""
            ========================================
            ğŸ“Š RESOURCE METRICS - Job Starting
            ========================================
            Job: ${jobExecution.jobInstance.jobName}

            Initial Resources:
            - CPU Cores: ${runtime.availableProcessors()}
            - Max Memory: ${runtime.maxMemory() / 1024 / 1024} MB
            - Used Memory: ${(runtime.totalMemory() - runtime.freeMemory()) / 1024 / 1024} MB
            - Free Memory: ${runtime.freeMemory() / 1024 / 1024} MB
            - Thread Count: ${threadBean.threadCount}
            - Daemon Threads: ${threadBean.daemonThreadCount}
            ========================================
        """.trimIndent())
    }

    override fun afterJob(jobExecution: JobExecution) {
        val endSnapshot = captureResourceSnapshot()
        val startSnapshot = jobStartSnapshot ?: return

        val duration = Duration.between(jobExecution.startTime, jobExecution.endTime)
        val durationSeconds = duration.seconds.toDouble()

        // í‰ê·  ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        val avgMemoryUsed = (startSnapshot.memoryUsed + endSnapshot.memoryUsed) / 2
        val avgCpuLoad = (startSnapshot.cpuLoad + endSnapshot.cpuLoad) / 2

        // Micrometerì— ê¸°ë¡
        meterRegistry.gauge(
            "batch.job.cpu.utilization",
            listOf(
                io.micrometer.core.instrument.Tag.of("job", jobExecution.jobInstance.jobName),
                io.micrometer.core.instrument.Tag.of("status", jobExecution.status.name)
            ),
            avgCpuLoad * 100  // í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        )

        meterRegistry.gauge(
            "batch.job.memory.used.mb",
            listOf(
                io.micrometer.core.instrument.Tag.of("job", jobExecution.jobInstance.jobName)
            ),
            avgMemoryUsed / 1024.0 / 1024.0
        )

        // ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­
        val totalProcessed = jobExecution.stepExecutions.sumOf { it.writeCount }
        val throughput = totalProcessed / durationSeconds

        meterRegistry.gauge(
            "batch.job.throughput.items_per_sec",
            listOf(
                io.micrometer.core.instrument.Tag.of("job", jobExecution.jobInstance.jobName)
            ),
            throughput
        )

        // ğŸ”¥ ì»´í“¨íŒ… íš¨ìœ¨ì„± ë¶„ì„
        val cpuUtilization = avgCpuLoad * 100
        val efficiency = when {
            cpuUtilization < 20 -> "ğŸ”´ IDLE (I/O bound)"
            cpuUtilization < 50 -> "ğŸŸ¡ UNDER-UTILIZED"
            cpuUtilization < 80 -> "ğŸŸ¢ OPTIMAL"
            else -> "ğŸ”´ CPU SATURATED"
        }

        log.info("""
            ========================================
            ğŸ“Š RESOURCE METRICS - Job Completed
            ========================================
            Job: ${jobExecution.jobInstance.jobName}
            Duration: ${durationSeconds}s

            ğŸ–¥ï¸  CPU Metrics:
            - Average CPU Load: ${String.format("%.2f", avgCpuLoad * 100)}%
            - Efficiency: $efficiency
            - Available Cores: ${runtime.availableProcessors()}

            ğŸ’¾ Memory Metrics:
            - Peak Memory Used: ${endSnapshot.memoryUsed / 1024 / 1024} MB
            - Average Memory: ${avgMemoryUsed / 1024 / 1024} MB
            - Max Available: ${runtime.maxMemory() / 1024 / 1024} MB
            - Memory Utilization: ${String.format("%.2f", (avgMemoryUsed.toDouble() / runtime.maxMemory()) * 100)}%

            ğŸ§µ Thread Metrics:
            - Peak Threads: ${endSnapshot.threadCount}
            - Waiting Threads: ${endSnapshot.waitingThreads}
            - Thread Utilization: ${String.format("%.2f", (endSnapshot.threadCount.toDouble() / runtime.availableProcessors()) * 100)}%

            ğŸ“ˆ Processing Metrics:
            - Total Processed: $totalProcessed items
            - Throughput: ${String.format("%.2f", throughput)} items/sec
            - Cost per Item (CPU time): ${String.format("%.4f", durationSeconds / totalProcessed)}s

            âš ï¸  Bottleneck Analysis:
            ${analyzeBottleneck(avgCpuLoad, endSnapshot)}
            ========================================
        """.trimIndent())

        // CSV í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥ (ë¶„ì„ ìš©ì´)
        log.info("RESOURCE_METRICS_CSV," +
                "${jobExecution.jobInstance.jobName}," +
                "${jobExecution.jobExecutionId}," +
                "${durationSeconds}," +
                "${String.format("%.2f", avgCpuLoad * 100)}," +
                "${avgMemoryUsed / 1024 / 1024}," +
                "${endSnapshot.threadCount}," +
                "${endSnapshot.waitingThreads}," +
                "${totalProcessed}," +
                "${String.format("%.2f", throughput)}")
    }

    private fun captureResourceSnapshot(): ResourceSnapshot {
        // CPU ì‚¬ìš©ë¥  (0.0 ~ 1.0)
        val cpuLoad = when (osBean) {
            is com.sun.management.OperatingSystemMXBean ->
                osBean.processCpuLoad
            else -> -1.0
        }

        // ë©”ëª¨ë¦¬
        val memoryUsed = runtime.totalMemory() - runtime.freeMemory()
        val memoryFree = runtime.freeMemory()

        // ìŠ¤ë ˆë“œ
        val threadCount = threadBean.threadCount
        val threadIds = threadBean.allThreadIds
        val waitingThreads = threadIds.count { id ->
            val info = threadBean.getThreadInfo(id)
            info?.threadState == Thread.State.WAITING ||
            info?.threadState == Thread.State.TIMED_WAITING
        }

        return ResourceSnapshot(
            timestamp = System.currentTimeMillis(),
            cpuLoad = cpuLoad,
            memoryUsed = memoryUsed,
            memoryFree = memoryFree,
            threadCount = threadCount,
            waitingThreads = waitingThreads
        )
    }

    private fun analyzeBottleneck(cpuLoad: Double, snapshot: ResourceSnapshot): String {
        val issues = mutableListOf<String>()

        // CPU ë¶„ì„
        if (cpuLoad < 0.2) {
            issues.add("- ğŸ”´ CPU Idle (${String.format("%.1f", cpuLoad * 100)}%) â†’ I/O Bound (ë„¤íŠ¸ì›Œí¬/DB ëŒ€ê¸°)")
        }

        // ë©”ëª¨ë¦¬ ë¶„ì„
        val memoryUsage = snapshot.memoryUsed.toDouble() / runtime.maxMemory()
        if (memoryUsage > 0.8) {
            issues.add("- ğŸ”´ High Memory Usage (${String.format("%.1f", memoryUsage * 100)}%) â†’ GC ì˜¤ë²„í—¤ë“œ")
        }

        // ìŠ¤ë ˆë“œ ë¶„ì„
        val waitingRatio = snapshot.waitingThreads.toDouble() / snapshot.threadCount
        if (waitingRatio > 0.5) {
            issues.add("- ğŸ”´ ${snapshot.waitingThreads}/${snapshot.threadCount} threads waiting â†’ External I/O Bottleneck")
        }

        return if (issues.isEmpty()) {
            "âœ… No obvious bottleneck detected"
        } else {
            issues.joinToString("\n")
        }
    }

    override fun beforeStep(stepExecution: StepExecution) {
        stepSnapshots[stepExecution.id] = captureResourceSnapshot()
    }

    override fun afterStep(stepExecution: StepExecution): org.springframework.batch.core.ExitStatus {
        // Stepë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ë„ ê¸°ë¡ ê°€ëŠ¥
        return stepExecution.exitStatus
    }

    companion object {
        private val log = org.slf4j.LoggerFactory.getLogger(ResourceMetricsListener::class.java)
    }
}
```

---

### ë„êµ¬ 2: íšŒì‚¬ë³„ ì²˜ë¦¬ ì‹œê°„ ìƒì„¸ ì¸¡ì • (Data Skew ë¶„ì„)

```kotlin
// batch/src/main/kotlin/com/techinsights/batch/processor/SkewAnalysisProcessor.kt

package com.techinsights.batch.processor

import com.techinsights.batch.crawling.PostCrawlingService
import com.techinsights.domain.dto.company.CompanyDto
import com.techinsights.domain.dto.post.PostDto
import io.micrometer.core.instrument.MeterRegistry
import io.micrometer.core.instrument.Timer
import kotlinx.coroutines.runBlocking
import org.springframework.batch.item.ItemProcessor
import org.springframework.stereotype.Component
import java.util.concurrent.ConcurrentHashMap
import kotlin.math.sqrt

@Component
class SkewAnalysisProcessor(
    private val postCrawlingService: PostCrawlingService,
    private val meterRegistry: MeterRegistry
) : ItemProcessor<CompanyDto, List<PostDto>> {

    companion object {
        private val log = org.slf4j.LoggerFactory.getLogger(SkewAnalysisProcessor::class.java)

        // íšŒì‚¬ë³„ ì²˜ë¦¬ ì‹œê°„ (ëª¨ë“  ì‹¤í–‰ ëˆ„ì )
        private val companyDurations = ConcurrentHashMap<String, MutableList<Long>>()

        // í˜„ì¬ ì‹¤í–‰ì˜ íšŒì‚¬ë³„ ì‹œê°„
        private val currentRunDurations = ConcurrentHashMap<String, Long>()
    }

    override fun process(company: CompanyDto): List<PostDto> {
        val startTime = System.currentTimeMillis()

        return runBlocking {
            try {
                // Timerë¡œ ì¸¡ì •
                val timer = Timer.sample()

                val result = postCrawlingService.processCrawledData(company)

                val duration = System.currentTimeMillis() - startTime

                // ê¸°ë¡
                companyDurations
                    .computeIfAbsent(company.name) { mutableListOf() }
                    .add(duration)

                currentRunDurations[company.name] = duration

                // Micrometerì— ê¸°ë¡
                timer.stop(meterRegistry.timer(
                    "batch.company.processing.time",
                    "company", company.name,
                    "status", "success"
                ))

                meterRegistry.counter(
                    "batch.company.posts.count",
                    "company", company.name
                ).increment(result.size.toDouble())

                log.info("âœ… ${company.name}: ${result.size} posts in ${duration}ms (${duration/1000}s)")

                result
            } catch (e: Exception) {
                val duration = System.currentTimeMillis() - startTime

                currentRunDurations[company.name] = duration

                meterRegistry.timer(
                    "batch.company.processing.time",
                    "company", company.name,
                    "status", "failed"
                ).record(duration, java.util.concurrent.TimeUnit.MILLISECONDS)

                log.error("âŒ ${company.name} FAILED after ${duration}ms: ${e.message}")
                throw e
            }
        }
    }

    // Job ì¢…ë£Œ í›„ í˜¸ì¶œ (JobExecutionListenerì—ì„œ)
    fun analyzeSkew() {
        if (currentRunDurations.isEmpty()) return

        val durations = currentRunDurations.values.toList()
        val sorted = durations.sorted()

        // í†µê³„ ê³„ì‚°
        val min = sorted.minOrNull() ?: 0
        val max = sorted.maxOrNull() ?: 0
        val mean = durations.average()
        val median = sorted[sorted.size / 2]

        // í‘œì¤€í¸ì°¨
        val variance = durations.map { (it - mean) * (it - mean) }.average()
        val stdDev = sqrt(variance)

        // Percentiles
        val p50 = sorted[(sorted.size * 0.50).toInt()]
        val p95 = sorted[(sorted.size * 0.95).toInt()]
        val p99 = sorted[(sorted.size * 0.99).toInt()]

        // Long Tail ë¶„ì„ (ìƒìœ„ 20%ê°€ ì „ì²´ì˜ ëª‡ %ë¥¼ ì°¨ì§€?)
        val top20Percent = sorted.takeLast((sorted.size * 0.2).toInt())
        val top20Sum = top20Percent.sum()
        val totalSum = sorted.sum()
        val top20Contribution = (top20Sum.toDouble() / totalSum) * 100

        // Skewness ê³„ì‚° (ì™œë„)
        val skew = if (sorted.size > 2) {
            val n = sorted.size
            val m3 = durations.map { val d = it - mean; d * d * d }.sum() / n
            val s3 = stdDev * stdDev * stdDev
            m3 / s3
        } else 0.0

        log.info("""
            ========================================
            ğŸ“Š DATA SKEW ANALYSIS
            ========================================
            Total Companies: ${durations.size}

            â±ï¸  Processing Time Distribution:
            - Min: ${min}ms (${min/1000}s)
            - P50 (Median): ${median}ms (${median/1000}s)
            - Mean: ${String.format("%.2f", mean)}ms
            - P95: ${p95}ms (${p95/1000}s)
            - P99: ${p99}ms (${p99/1000}s)
            - Max: ${max}ms (${max/1000}s)
            - Std Dev: ${String.format("%.2f", stdDev)}ms

            ğŸ¯ Skewness Analysis:
            - Skewness: ${String.format("%.2f", skew)} ${interpretSkewness(skew)}
            - Max/Median Ratio: ${String.format("%.2f", max.toDouble() / median)}x
            - Top 20% Contribution: ${String.format("%.1f", top20Contribution)}%

            ğŸ”´ Slowest Companies (Top 5):
            ${getSlowestCompanies(5)}

            ğŸŸ¢ Fastest Companies (Top 5):
            ${getFastestCompanies(5)}

            âš ï¸  Recommendation:
            ${generateRecommendation(skew, max.toDouble() / median, top20Contribution)}
            ========================================
        """.trimIndent())

        // CSV ì¶œë ¥
        currentRunDurations.forEach { (company, duration) ->
            log.info("SKEW_CSV,$company,$duration")
        }

        // í˜„ì¬ ì‹¤í–‰ ë°ì´í„° ì´ˆê¸°í™”
        currentRunDurations.clear()
    }

    private fun interpretSkewness(skew: Double): String = when {
        skew < -1 -> "ğŸ”´ Highly Left-Skewed (ëŒ€ë¶€ë¶„ ëŠë¦¼)"
        skew < -0.5 -> "ğŸŸ¡ Left-Skewed"
        skew > 1 -> "ğŸ”´ Highly Right-Skewed (ì†Œìˆ˜ë§Œ ë§¤ìš° ëŠë¦¼)"
        skew > 0.5 -> "ğŸŸ¡ Right-Skewed"
        else -> "ğŸŸ¢ Symmetric (ê· ë“± ë¶„í¬)"
    }

    private fun getSlowestCompanies(n: Int): String {
        return currentRunDurations.entries
            .sortedByDescending { it.value }
            .take(n)
            .mapIndexed { idx, (company, duration) ->
                "${idx + 1}. $company: ${duration}ms (${duration/1000}s)"
            }
            .joinToString("\n            ")
    }

    private fun getFastestCompanies(n: Int): String {
        return currentRunDurations.entries
            .sortedBy { it.value }
            .take(n)
            .mapIndexed { idx, (company, duration) ->
                "${idx + 1}. $company: ${duration}ms (${duration/1000}s)"
            }
            .joinToString("\n            ")
    }

    private fun generateRecommendation(
        skew: Double,
        maxMedianRatio: Double,
        top20Contribution: Double
    ): String {
        val issues = mutableListOf<String>()

        if (maxMedianRatio > 5) {
            issues.add("- ğŸ”´ Max/Median ratio ${String.format("%.1f", maxMedianRatio)}x â†’ íŠ¹ì • íšŒì‚¬ê°€ ì „ì²´ ì‹œê°„ ì§€ë°°")
        }

        if (top20Contribution > 60) {
            issues.add("- ğŸ”´ ìƒìœ„ 20% íšŒì‚¬ê°€ ì „ì²´ì˜ ${String.format("%.1f", top20Contribution)}% ì°¨ì§€ â†’ ì‹¬ê°í•œ Data Skew")
        }

        if (skew > 1) {
            issues.add("- ğŸŸ¡ Right-Skewed ë¶„í¬ â†’ ì†Œìˆ˜ íšŒì‚¬ë§Œ ì˜¤ë˜ ê±¸ë¦¼ â†’ ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ê°œì„  íš¨ê³¼ ì œí•œì ")
        }

        return if (issues.isEmpty()) {
            "âœ… ì²˜ë¦¬ ì‹œê°„ì´ ê· ë“±í•˜ê²Œ ë¶„í¬ë¨ â†’ ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ ê·¹ëŒ€í™” ê°€ëŠ¥"
        } else {
            issues.joinToString("\n            ")
        }
    }
}
```

---

### ë„êµ¬ 3: ë¹„ìš© ë¶„ì„ (Cost per Record)

```kotlin
// batch/src/main/kotlin/com/techinsights/batch/listener/CostAnalysisListener.kt

package com.techinsights.batch.listener

import org.springframework.batch.core.JobExecution
import org.springframework.batch.core.JobExecutionListener
import org.springframework.stereotype.Component
import java.time.Duration

@Component
class CostAnalysisListener : JobExecutionListener {

    // AWS EC2 t2.micro ë¹„ìš© (ì„œìš¸ ë¦¬ì „, On-Demand, 2024 ê¸°ì¤€)
    private val ec2HourlyCost = 0.0136  // USD per hour

    // Gemini API ë¹„ìš© (ì˜ˆì‹œ)
    // https://ai.google.dev/pricing
    private val geminiFlashSummaryCost = 0.000075  // per 1K characters input
    private val geminiEmbeddingCost = 0.00001      // per 1K characters

    override fun afterJob(jobExecution: JobExecution) {
        val duration = Duration.between(jobExecution.startTime, jobExecution.endTime)
        val durationHours = duration.seconds / 3600.0

        val stepExecutions = jobExecution.stepExecutions

        // ì²˜ë¦¬ëŸ‰
        val totalRead = stepExecutions.sumOf { it.readCount }
        val totalWrite = stepExecutions.sumOf { it.writeCount }

        // ğŸ”¥ ì¸í”„ë¼ ë¹„ìš© ê³„ì‚°
        val ec2Cost = durationHours * ec2HourlyCost

        // ğŸ”¥ API ë¹„ìš© ì¶”ì • (ì‹¤ì œë¡œëŠ” ë¡œê·¸ë‚˜ API ëª¨ë‹ˆí„°ë§ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        val estimatedSummaryCalls = totalWrite  // ê° postë§ˆë‹¤ ìš”ì•½
        val estimatedEmbeddingCalls = totalWrite  // ê° postë§ˆë‹¤ ì„ë² ë”©

        // í‰ê·  post ê¸¸ì´ 5000ì ê°€ì •
        val avgPostLength = 5000
        val summaryCost = (estimatedSummaryCalls * avgPostLength / 1000.0) * geminiFlashSummaryCost
        val embeddingCost = (estimatedEmbeddingCalls * avgPostLength / 1000.0) * geminiEmbeddingCost

        val totalApiCost = summaryCost + embeddingCost
        val totalCost = ec2Cost + totalApiCost

        // ğŸ”¥ Cost per Record
        val costPerPost = if (totalWrite > 0) totalCost / totalWrite else 0.0

        log.info("""
            ========================================
            ğŸ’° COST ANALYSIS
            ========================================
            Job: ${jobExecution.jobInstance.jobName}
            Duration: ${String.format("%.4f", durationHours)}h

            ğŸ“Š Processing Stats:
            - Total Posts Processed: $totalWrite
            - Total API Calls: ${estimatedSummaryCalls + estimatedEmbeddingCalls}

            ğŸ’µ Infrastructure Cost:
            - EC2 t2.micro: $${String.format("%.6f", ec2Cost)} (${String.format("%.2f", durationHours)}h Ã— $${ec2HourlyCost}/h)

            ğŸ’µ API Cost (Estimated):
            - Gemini Summary: $${String.format("%.6f", summaryCost)}
            - Gemini Embedding: $${String.format("%.6f", embeddingCost)}
            - Total API: $${String.format("%.6f", totalApiCost)}

            ğŸ’° Total Cost:
            - Job Total: $${String.format("%.6f", totalCost)}
            - Cost per Post: $${String.format("%.8f", costPerPost)}

            ğŸ“ˆ Monthly Projection (30 runs):
            - Infrastructure: $${String.format("%.2f", ec2Cost * 30)}
            - API: $${String.format("%.2f", totalApiCost * 30)}
            - Total: $${String.format("%.2f", totalCost * 30)}

            âš ï¸  Cost Efficiency:
            ${analyzeCostEfficiency(costPerPost, durationHours, totalWrite)}
            ========================================
        """.trimIndent())

        // CSV ì¶œë ¥
        log.info("COST_CSV," +
                "${jobExecution.jobInstance.jobName}," +
                "${jobExecution.jobExecutionId}," +
                "${String.format("%.6f", totalCost)}," +
                "${String.format("%.8f", costPerPost)}," +
                "${totalWrite}," +
                "${String.format("%.4f", durationHours)}")
    }

    private fun analyzeCostEfficiency(
        costPerPost: Double,
        durationHours: Double,
        totalWrite: Long
    ): String {
        val issues = mutableListOf<String>()

        // ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰
        val postsPerHour = if (durationHours > 0) totalWrite / durationHours else 0.0

        if (postsPerHour < 100) {
            issues.add("- ğŸ”´ ë‚®ì€ ì²˜ë¦¬ëŸ‰ (${String.format("%.1f", postsPerHour)} posts/h) â†’ ì¸í”„ë¼ ë¹„ìš© ë¹„íš¨ìœ¨")
        }

        if (costPerPost > 0.001) {
            issues.add("- ğŸŸ¡ Postë‹¹ ë¹„ìš© ë†’ìŒ ($${String.format("%.6f", costPerPost)}) â†’ API í˜¸ì¶œ ìµœì í™” í•„ìš”")
        }

        return if (issues.isEmpty()) {
            "âœ… ë¹„ìš© íš¨ìœ¨ì  (ì‹œê°„ë‹¹ ${String.format("%.1f", postsPerHour)} posts ì²˜ë¦¬)"
        } else {
            issues.joinToString("\n            ")
        }
    }

    override fun beforeJob(jobExecution: JobExecution) {
        // ì‹œì‘ ì‹œ ë¹„ìš© ì¶”ì •
        log.info("ğŸ’° Cost tracking started for ${jobExecution.jobInstance.jobName}")
    }

    companion object {
        private val log = org.slf4j.LoggerFactory.getLogger(CostAnalysisListener::class.java)
    }
}
```

---

## ğŸ“‹ ì„¤ì • í†µí•©

### Step 1: Listener ë“±ë¡

```kotlin
// batch/src/main/kotlin/com/techinsights/batch/config/PostCrawlingBatchConfig.kt

@Configuration
class PostCrawlingBatchConfig (
  private val jobRepository: JobRepository,
  private val transactionManager: PlatformTransactionManager,
  private val companyReader: CompanyReader,
  private val skewAnalysisProcessor: SkewAnalysisProcessor,  // ë³€ê²½
  private val rawPostWriter: RawPostWriter,
  private val properties: PostCrawlingBatchProperties,
  private val loggingJobExecutionListener: LoggingJobExecutionListener,
  private val resourceMetricsListener: ResourceMetricsListener,  // ì¶”ê°€
  private val costAnalysisListener: CostAnalysisListener  // ì¶”ê°€
){

  @Bean
  fun crawlPostJob(@Qualifier("crawlPostStep") crawlPostStep: Step): Job =
    JobBuilder(properties.jobName, jobRepository)
      .incrementer(RunIdIncrementer())
      .listener(loggingJobExecutionListener)
      .listener(resourceMetricsListener)  // ì¶”ê°€
      .listener(costAnalysisListener)  // ì¶”ê°€
      .listener(object : JobExecutionListener {
          override fun afterJob(jobExecution: JobExecution) {
              skewAnalysisProcessor.analyzeSkew()  // Skew ë¶„ì„
          }
      })
      .start(crawlPostStep)
      .build()

  @Bean
  fun crawlPostStep(): Step = StepBuilder(properties.stepName, jobRepository)
    .chunk<CompanyDto, List<PostDto>>(properties.chunkSize, transactionManager)
    .reader(companyReader)
    .processor(skewAnalysisProcessor)  // ë³€ê²½
    .writer(rawPostWriter)
    .faultTolerant()
    .retry(Exception::class.java)
    .retryLimit(properties.retryLimit)
    .skip(Exception::class.java)
    .skipLimit(10)
    .build()
}
```

---

## ğŸš€ ì‹¤í–‰ ë° ë°ì´í„° ìˆ˜ì§‘

### Step 1: ë¹Œë“œ ë° ë°°í¬

```bash
./gradlew :batch:build

# ì„œë²„ì— ë°°í¬ (ë˜ëŠ” ë¡œì»¬ ì‹¤í–‰)
```

### Step 2: ë°°ì¹˜ ì‹¤í–‰

```bash
java -jar batch.jar --spring.batch.job.names=crawlPostJob
```

### Step 3: ë¡œê·¸ í™•ì¸

```bash
tail -f /var/log/batch/batch.log | grep -E "RESOURCE_METRICS|SKEW|COST"
```

**ì˜ˆìƒ ì¶œë ¥:**

```
========================================
ğŸ“Š RESOURCE METRICS - Job Completed
========================================
Job: crawlPostJob
Duration: 892s

ğŸ–¥ï¸  CPU Metrics:
- Average CPU Load: 12.34%
- Efficiency: ğŸ”´ IDLE (I/O bound)
- Available Cores: 1

ğŸ’¾ Memory Metrics:
- Peak Memory Used: 450 MB
- Average Memory: 380 MB
- Memory Utilization: 45.23%

ğŸ§µ Thread Metrics:
- Peak Threads: 25
- Waiting Threads: 18
- Thread Utilization: 72.00%

ğŸ“ˆ Processing Metrics:
- Total Processed: 120 items
- Throughput: 0.13 items/sec
- Cost per Item (CPU time): 7.43s

âš ï¸  Bottleneck Analysis:
- ğŸ”´ CPU Idle (12.3%) â†’ I/O Bound (ë„¤íŠ¸ì›Œí¬/DB ëŒ€ê¸°)
- ğŸ”´ 18/25 threads waiting â†’ External I/O Bottleneck
========================================

========================================
ğŸ“Š DATA SKEW ANALYSIS
========================================
Total Companies: 13

â±ï¸  Processing Time Distribution:
- Min: 15000ms (15s)
- P50 (Median): 45000ms (45s)
- Mean: 68615.38ms
- P95: 180000ms (180s)
- P99: 210000ms (210s)
- Max: 250000ms (250s)
- Std Dev: 62345.12ms

ğŸ¯ Skewness Analysis:
- Skewness: 1.23 ğŸ”´ Highly Right-Skewed (ì†Œìˆ˜ë§Œ ë§¤ìš° ëŠë¦¼)
- Max/Median Ratio: 5.56x
- Top 20% Contribution: 68.5%

ğŸ”´ Slowest Companies (Top 5):
1. Woowahan: 250000ms (250s)
2. Kakao: 180000ms (180s)
3. Naver: 120000ms (120s)
4. Toss: 60000ms (60s)
5. Kurly: 55000ms (55s)

ğŸŸ¢ Fastest Companies (Top 5):
1. CompanyA: 15000ms (15s)
2. CompanyB: 18000ms (18s)
3. CompanyC: 25000ms (25s)
4. CompanyD: 30000ms (30s)
5. CompanyE: 35000ms (35s)

âš ï¸  Recommendation:
- ğŸ”´ Max/Median ratio 5.6x â†’ íŠ¹ì • íšŒì‚¬ê°€ ì „ì²´ ì‹œê°„ ì§€ë°°
- ğŸ”´ ìƒìœ„ 20% íšŒì‚¬ê°€ ì „ì²´ì˜ 68.5% ì°¨ì§€ â†’ ì‹¬ê°í•œ Data Skew
- ğŸŸ¡ Right-Skewed ë¶„í¬ â†’ ì†Œìˆ˜ íšŒì‚¬ë§Œ ì˜¤ë˜ ê±¸ë¦¼ â†’ ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ê°œì„  íš¨ê³¼ ì œí•œì 
========================================

========================================
ğŸ’° COST ANALYSIS
========================================
Job: crawlPostJob
Duration: 0.2478h

ğŸ“Š Processing Stats:
- Total Posts Processed: 120
- Total API Calls: 240

ğŸ’µ Infrastructure Cost:
- EC2 t2.micro: $0.003370 (0.25h Ã— $0.0136/h)

ğŸ’µ API Cost (Estimated):
- Gemini Summary: $0.045000
- Gemini Embedding: $0.006000
- Total API: $0.051000

ğŸ’° Total Cost:
- Job Total: $0.054370
- Cost per Post: $0.00045308

ğŸ“ˆ Monthly Projection (30 runs):
- Infrastructure: $0.10
- API: $1.53
- Total: $1.63

âš ï¸  Cost Efficiency:
- ğŸ”´ ë‚®ì€ ì²˜ë¦¬ëŸ‰ (484.3 posts/h) â†’ ì¸í”„ë¼ ë¹„ìš© ë¹„íš¨ìœ¨
========================================
```

---

## ğŸ“Š ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŠ¸

### ìˆ˜ì§‘ëœ CSV ë°ì´í„° ì¶”ì¶œ

```bash
# ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
grep "RESOURCE_METRICS_CSV" /var/log/batch/batch.log > resource_metrics.csv

# Skew ë°ì´í„°
grep "SKEW_CSV" /var/log/batch/batch.log > skew_data.csv

# ë¹„ìš© ë°ì´í„°
grep "COST_CSV" /var/log/batch/batch.log > cost_data.csv
```

### Excel/Google Sheets ë¶„ì„

**resource_metrics.csv:**
```csv
RESOURCE_METRICS_CSV,crawlPostJob,12345,892.5,12.34,380,25,18,120,0.13
```

í”¼ë²— í…Œì´ë¸”:
- Xì¶•: ì‹¤í–‰ ì¼ì
- Yì¶•: CPU ì‚¬ìš©ë¥ , ì²˜ë¦¬ëŸ‰
- ê·¸ë˜í”„: ì‹œê°„ì— ë”°ë¥¸ CPU ì‚¬ìš©ë¥  ì¶”ì´

---

## ğŸ¯ ìµœì¢… ë¦¬í¬íŠ¸ ì˜ˆì‹œ

```markdown
# Batch System ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸

## 1. ì»´í“¨íŒ… íš¨ìœ¨ì„± ë¶„ì„

### í˜„í™©
- **CPU ì‚¬ìš©ë¥ **: í‰ê·  12.3% (30íšŒ ì¸¡ì •)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: í‰ê·  45.2%
- **ìŠ¤ë ˆë“œ ëŒ€ê¸° ë¹„ìœ¨**: 72% (18/25 threads waiting)

### ğŸ”´ Critical Finding: I/O Bound
**ê·¼ê±°:**
- CPUê°€ 12.3%ë§Œ ì‚¬ìš©ë˜ê³  88%ëŠ” ìœ íœ´ ìƒíƒœ
- 25ê°œ ìŠ¤ë ˆë“œ ì¤‘ 18ê°œê°€ WAITING ìƒíƒœ
- ì²˜ë¦¬ëŸ‰ 0.13 items/sec (ëª©í‘œ 10 items/secì˜ 1.3%)

**ì›ì¸:**
- ì™¸ë¶€ API/ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œê°„ì´ ì „ì²´ì˜ 88%
- ìˆœì°¨ ì²˜ë¦¬ë¡œ ì¸í•œ ëŒ€ê¸° ì‹œê°„ ëˆ„ì 

**ê°œì„ ì•ˆ:**
- ë³‘ë ¬ ì²˜ë¦¬ ë„ì… â†’ CPU ì‚¬ìš©ë¥  70% ëª©í‘œ
- ì˜ˆìƒ íš¨ê³¼: ì²˜ë¦¬ ì‹œê°„ 85% ë‹¨ì¶•

---

## 2. Data Skew ë¶„ì„

### í˜„í™©
- **Max/Median ë¹„ìœ¨**: 5.56x
- **Skewness**: 1.23 (Right-Skewed)
- **ìƒìœ„ 20% ê¸°ì—¬ë„**: 68.5%

### ğŸ”´ Critical Finding: ì‹¬ê°í•œ Data Skew
**ê·¼ê±°:**
- Woowahan: 250ì´ˆ vs ì¤‘ê°„ê°’ 45ì´ˆ (5.6ë°° ì°¨ì´)
- ìƒìœ„ 3ê°œ íšŒì‚¬(23%)ê°€ ì „ì²´ ì‹œê°„ì˜ 68.5% ì°¨ì§€
- ê°€ì¥ ëŠë¦° íšŒì‚¬ê°€ ì „ì²´ ë°°ì¹˜ ì‹œê°„ì„ ì§€ë°°

**ê°œì„ ì•ˆ:**
1. Woowahan íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (300ì´ˆ â†’ 30ì´ˆ)
   - ì˜ˆìƒ íš¨ê³¼: ì „ì²´ ì‹œê°„ 220ì´ˆ ë‹¨ì¶• (25%)
2. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëŠë¦° íšŒì‚¬ ê²©ë¦¬
   - ì˜ˆìƒ íš¨ê³¼: ì „ì²´ ì‹œê°„ 60% ë‹¨ì¶•

---

## 3. ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„

### í˜„í™©
- **Postë‹¹ ë¹„ìš©**: $0.000453
- **ì›”ê°„ ì´ ë¹„ìš©**: $1.63 (30íšŒ ì‹¤í–‰)
  - ì¸í”„ë¼: $0.10
  - API: $1.53
- **ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰**: 484 posts/h

### ğŸŸ¡ Warning: ë‚®ì€ ì²˜ë¦¬ëŸ‰
**ê·¼ê±°:**
- ëª©í‘œ ì‹œê°„ë‹¹ 3600 posts vs ì‹¤ì œ 484 posts (13% ìˆ˜ì¤€)
- EC2ê°€ 15ë¶„ ëŒì•„ì„œ $0.0034 vs ëª©í‘œ 2ë¶„ ($0.00045)
- **ì‹œê°„ë‹¹ ì¸í”„ë¼ ë¹„ìš© 7.5ë°° ì´ˆê³¼**

**ê°œì„  í›„ ì˜ˆìƒ:**
- ì²˜ë¦¬ ì‹œê°„ 15ë¶„ â†’ 2ë¶„ (86% ë‹¨ì¶•)
- ì›”ê°„ ë¹„ìš© $1.63 â†’ $0.23 (86% ì ˆê°)
- **ì—°ê°„ $16.8 ì ˆê°**
```

---

ì´ì œ **"ëŠë¦¬ë‹¤"ê°€ ì•„ë‹ˆë¼ "CPU 12%ì¸ë° ì™œ 15ë¶„ì´ë‚˜ ê±¸ë¦¬ì£ ?"**ë¼ê³  ë°ì´í„°ë¡œ ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¯
